{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import urllib.parse\n",
    "from typing import List, Dict, Union\n",
    "from httpx import AsyncClient, Response\n",
    "from parsel import Selector\n",
    "from urllib.parse import urlencode, quote_plus\n",
    "# from loguru import logger as log\n",
    "\n",
    "# initialize an async httpx client\n",
    "client = AsyncClient(\n",
    "    # enable http2\n",
    "    http2=True,\n",
    "    # add basic browser like headers to prevent getting blocked\n",
    "    headers={\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Cookie\": \"intl_splash=false\"\n",
    "    },\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_search(response: Response) -> List[Dict]:\n",
    "    \"\"\"parse search data from search pages\"\"\"\n",
    "    selector = Selector(response.text)\n",
    "    data = []\n",
    "    for item in selector.xpath(\"//ol[@class='sku-item-list']/li[@class='sku-item']\"):\n",
    "        name = item.xpath(\".//h4[@class='sku-title']/a/text()\").get()\n",
    "        link = item.xpath(\".//h4[@class='sku-title']/a/@href\").get()\n",
    "        price = item.xpath(\".//div[@data-testid='customer-price']/span/text()\").get()\n",
    "        price = int(price[price.index(\"$\") + 1:].replace(\",\", \"\").replace(\".\", \"\")) // 100 if price else None\n",
    "        original_price = item.xpath(\".//div[@data-testid='regular-price']/span/text()\").get()\n",
    "        original_price = int(original_price[original_price.index(\"$\") + 1:].replace(\",\", \"\").replace(\".\", \"\")) // 100 if original_price else None\n",
    "        sku = item.xpath(\".//div[@class='sku-model']/div[2]/span[@class='sku-value']/text()\").get()\n",
    "        model = item.xpath(\".//div[@class='sku-model']/div[1]/span[@class='sku-value']/text()\").get()\n",
    "        rating = item.xpath(\".//p[contains(text(),'out of 5')]/text()\").get()\n",
    "        rating_count = item.xpath(\".//span[contains(@class,'c-reviews')]/text()\").get()\n",
    "        is_sold_out = bool(item.xpath(\".//strong[text()='Sold Out']\").get())\n",
    "        image = item.xpath(\".//img[contains(@class,'product-image')]/@src\").get()\n",
    "\n",
    "        data.append({\n",
    "            \"name\": name,\n",
    "            \"link\": \"https://www.bestbuy.com\" + link,\n",
    "            \"image\": image,\n",
    "            \"sku\": sku,\n",
    "            \"model\": model,\n",
    "            \"price\": price,\n",
    "            \"original_price\": original_price,\n",
    "            \"save\": f\"{round((1 - price / original_price) * 100, 2):.2f}%\" if price and original_price else None,\n",
    "            \"rating\": float(rating[rating.index(\" \"):rating.index(\" out\")].strip()) if rating else None,\n",
    "            \"rating_count\": int(rating_count.replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\")) if rating_count and rating_count != \"Not Yet Reviewed\" else None,\n",
    "            \"is_sold_out\": is_sold_out,\n",
    "        })\n",
    "    total_count = selector.xpath(\"//span[@class='item-count']/text()\").get()\n",
    "    total_count = int(total_count.split(\" \")[0]) // 18 # convert the total items to pages, 18 items in each page\n",
    "\n",
    "    return {\"data\": data, \"total_count\": total_count}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_search(\n",
    "        search_query: str, sort: Union[\"-bestsellingsort\", \"-Best-Discount\"] = None, max_pages=None\n",
    "        ) -> List[Dict]:\n",
    "    \"\"\"scrape search data from bestbuy search\"\"\"\n",
    "\n",
    "    def form_search_url(page_number: int):\n",
    "        \"\"\"form the search url\"\"\"\n",
    "        base_url = \"https://www.bestbuy.com/site/searchpage.jsp?\"\n",
    "        # search parameters\n",
    "        params = {\n",
    "            \"st\": quote_plus(search_query),\n",
    "            \"sp\": sort, # None = best match\n",
    "            \"cp\": page_number\n",
    "        }\n",
    "        return base_url + urlencode(params)\n",
    "\n",
    "    first_page = await client.get(form_search_url(1))\n",
    "    data = parse_search(first_page)\n",
    "    search_data = data[\"data\"]\n",
    "    total_count = data[\"total_count\"]\n",
    "\n",
    "    # get the number of total search pages to scrape\n",
    "    if max_pages and max_pages < total_count:\n",
    "        total_count = max_pages\n",
    "\n",
    "    print(f\"scraping search pagination, {total_count - 1} more pages\")\n",
    "    # add the remaining pages to a scraping list to scrape them concurrently\n",
    "    to_scrape = [\n",
    "        client.get(form_search_url(page_number))\n",
    "        for page_number in range(2, total_count + 1)\n",
    "    ]\n",
    "    for response in asyncio.as_completed(to_scrape):\n",
    "        response = await response\n",
    "        data = parse_search(response)[\"data\"]\n",
    "        search_data.extend(data)\n",
    "    \n",
    "    print(f\"scraped {len(search_data)} products from search pages\")\n",
    "    return search_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run():\n",
    "    search_data = await scrape_search(\n",
    "        search_query=\"macbook\",\n",
    "        max_pages=3\n",
    "    )\n",
    "    # save the results to a JSOn file\n",
    "    with open(\"search.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(search_data, file, indent=2, ensure_ascii=False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'asyncio' has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a416649eb695>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'asyncio' has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "asyncio.run(run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
